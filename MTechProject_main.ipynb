{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XawDAVUSdP_9"
      },
      "outputs": [],
      "source": [
        "#OmSaiRam\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "# import tensorflow.keras.preprocessing\n",
        "import itertools\n",
        "import os\n",
        "\n",
        "import matplotlib.pylab as plt\n",
        "import numpy as np\n",
        "\n",
        "# import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "import pandas as pd\n",
        "import cv2\n",
        "import math\n",
        "import random\n",
        "import shutil\n",
        "from sklearn.preprocessing import PowerTransformer\n",
        "from PIL import Image\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "print(\"TF version:\", tf.__version__)\n",
        "print(\"Hub version:\", hub.__version__)\n",
        "print(\"Gpu is\", \"available\" if tf.config.list_physical_devices('GPU') else \"NOT AVAILABLE\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "---"
      ],
      "metadata": {
        "id": "u_vkMwVMSDEz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import cv2\n",
        "import math\n",
        "import random\n",
        "import shutil\n",
        "from sklearn.preprocessing import PowerTransformer\n",
        "from PIL import Image\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "metadata": {
        "id": "W939vlynauYp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "Eo2jOfu3SEf4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "local_zip = './carhacking.zip'\n",
        "print(type(local_zip))\n",
        "zip_ref= zipfile.ZipFile(local_zip,'r')\n",
        "zip_ref.extractall('tmp/datacarhacking')\n",
        "zip_ref.close()"
      ],
      "metadata": {
        "id": "t-uWaX87BIqg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "jznDtAkPSFnZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import io\n",
        "\n",
        "df = pd.read_csv('/content/tmp/datacarhacking/carhacking.csv')\n",
        "df\n"
      ],
      "metadata": {
        "id": "pAcqp2TnVj5j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "9YC-SD-_SHmT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.Label.value_counts()"
      ],
      "metadata": {
        "id": "F6kBVIwghZiJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "RQ07P205SIZ4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "WZXqe1ZqSJBQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#scale down all the values of the numerics between 0 and 1\n",
        "numeric_features = df.dtypes[df.dtypes != 'object'].index\n",
        "scaler = PowerTransformer(method = 'box-cox')\n",
        "df[numeric_features] = df[numeric_features].apply(\n",
        "    lambda x: (x)\n",
        ")\n",
        "df.describe()"
      ],
      "metadata": {
        "id": "-4OAB7GwoVor"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "1LfECticSKpL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#Generate images for each classes\n",
        "df0=df[df['Label']=='R'].drop(['Label'],axis=1)\n",
        "df1=df[df['Label']=='RPM'].drop(['Label'],axis=1)\n",
        "df2=df[df['Label']=='gear'].drop(['Label'],axis=1)\n",
        "df3=df[df['Label']=='DoS'].drop(['Label'],axis=1)\n",
        "df4=df[df['Label']=='Fuzzy'].drop(['Label'],axis=1)\n"
      ],
      "metadata": {
        "id": "2WCablUmpsMT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "cbY3EZRySLgR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "count=0\n",
        "ims = []\n",
        "\n",
        "image_path = \"train/0/\"\n",
        "os.makedirs(image_path)\n",
        "\n",
        "for i in range(0, len(df0)):\n",
        "    count=count+1\n",
        "    if count<=27:\n",
        "        im=df0.iloc[i].values\n",
        "        ims=np.append(ims,im)\n",
        "    else:\n",
        "        ims=np.asarray(ims).reshape(9,9,3)\n",
        "        array = np.array(ims, dtype=np.uint16)\n",
        "        new_image = Image.fromarray(array, mode = 'RGBA')\n",
        "        new_image.save(image_path+str(i)+'.png')\n",
        "        count=0\n",
        "        ims = []"
      ],
      "metadata": {
        "id": "NWSgPm0OTNYh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#For class 1 RPM Spoofing Attack\n",
        "count=0\n",
        "ims = []\n",
        "\n",
        "image_path = \"train/1/\"\n",
        "os.makedirs(image_path)\n",
        "\n",
        "\n",
        "for i in range(0, len(df1)):\n",
        "    count=count+1\n",
        "    if count<=27:\n",
        "        im=df1.iloc[i].values\n",
        "        ims=np.append(ims,im)\n",
        "    else:\n",
        "        ims=np.array(ims).reshape(9,9,3)\n",
        "        array = np.array(ims, dtype=np.uint16)\n",
        "        new_image = Image.fromarray(array,mode = 'RGBA')\n",
        "        new_image.save(image_path+str(i)+'.png')\n",
        "        count=0\n",
        "        ims = []"
      ],
      "metadata": {
        "id": "CUjJQxOGFoz8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#For class 2 Gear Spoofing Attack\n",
        "count=0\n",
        "ims = []\n",
        "\n",
        "image_path = \"train/2/\"\n",
        "os.makedirs(image_path)\n",
        "\n",
        "\n",
        "for i in range(0, len(df2)):\n",
        "    count=count+1\n",
        "    if count<=27:\n",
        "        im=df2.iloc[i].values\n",
        "        ims=np.append(ims,im)\n",
        "    else:\n",
        "        ims=np.array(ims).reshape(9,9,3)\n",
        "        array = np.array(ims, dtype=np.uint8)\n",
        "        new_image = Image.fromarray(array)\n",
        "        new_image.save(image_path+str(i)+'.png')\n",
        "        count=0\n",
        "        ims = []"
      ],
      "metadata": {
        "id": "V8BX1YNQFoxX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "AnUwYXhXSMGo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#For class 3 Dos Attack\n",
        "count=0\n",
        "ims = []\n",
        "\n",
        "image_path = \"train/3/\"\n",
        "os.makedirs(image_path)\n",
        "\n",
        "\n",
        "for i in range(0, len(df3)):\n",
        "    count=count+1\n",
        "    if count<=27:\n",
        "        im=df3.iloc[i].values\n",
        "        ims=np.append(ims,im)\n",
        "    else:\n",
        "        ims=np.array(ims).reshape(9,9,3)\n",
        "        array = np.array(ims, dtype=np.uint8)\n",
        "        new_image = Image.fromarray(array)\n",
        "        new_image.save(image_path+str(i)+'.png')\n",
        "        count=0\n",
        "        ims = []"
      ],
      "metadata": {
        "id": "8hbPYIQQUHyn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "mHrib_p7SMrY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#For class 4 Fuzzy attack\n",
        "count=0\n",
        "ims = []\n",
        "\n",
        "image_path = \"train/4/\"\n",
        "os.makedirs(image_path)\n",
        "\n",
        "\n",
        "for i in range(0, len(df4)):\n",
        "    count=count+1\n",
        "    if count<=27:\n",
        "        im=df4.iloc[i].values\n",
        "        ims=np.append(ims,im)\n",
        "    else:\n",
        "        ims=np.asarray(ims).reshape(9,9,3)\n",
        "        array = np.array(ims, dtype=np.uint8)\n",
        "        new_image = Image.fromarray(array)\n",
        "        new_image.save(image_path+str(i)+'.png')\n",
        "        count=0\n",
        "        ims = []"
      ],
      "metadata": {
        "id": "e_Mzft99UYmD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "nBL932GoSNrS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create folders to store images\n",
        "Train_Dir='./train/'\n",
        "Val_Dir='./test/'\n",
        "allimgs=[]\n",
        "for subdir in os.listdir(Train_Dir):\n",
        "    for filename in os.listdir(os.path.join(Train_Dir,subdir)):\n",
        "        filepath=os.path.join(Train_Dir,subdir,filename)\n",
        "        allimgs.append(filepath)\n",
        "# print(len(allimgs)) # Print the total number of images\n",
        "print('Operation successfully executed.')"
      ],
      "metadata": {
        "id": "NRtxUj4YXQeN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "TbeZKS07SOcq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "From Here We can adjust the size of dataset"
      ],
      "metadata": {
        "id": "5gJjuH6eFNXm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#split a test set from the dataset, train/test size = 80%/20%\n",
        "Numbers=int(len(allimgs)/5) \t#size of test set (20%)\n",
        "\n",
        "def mymovefile(srcfile,dstfile):\n",
        "    if not os.path.isfile(srcfile):\n",
        "        print (\"%s not exist!\"%(srcfile))\n",
        "    else:\n",
        "        fpath,fname=os.path.split(dstfile)\n",
        "        if not os.path.exists(fpath):\n",
        "            os.makedirs(fpath)\n",
        "        shutil.move(srcfile,dstfile)"
      ],
      "metadata": {
        "id": "78eL7Yf3XR-L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "sqsMDNvuSPMR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the test set\n",
        "val_imgs=random.sample(allimgs,Numbers)\n",
        "for img in val_imgs:\n",
        "    dest_path=img.replace(Train_Dir,Val_Dir)\n",
        "    mymovefile(img,dest_path)\n",
        "print('Finish creating test set')"
      ],
      "metadata": {
        "id": "kvVBALj1XaUW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "Gf_PrCgDSP5i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#resize the images 224*224 for better CNN training\n",
        "def get_224(folder,dstdir):\n",
        "    imgfilepaths=[]\n",
        "    for root,dirs,imgs in os.walk(folder):\n",
        "        for thisimg in imgs:\n",
        "            thisimg_path=os.path.join(root,thisimg)\n",
        "            imgfilepaths.append(thisimg_path)\n",
        "    for thisimg_path in imgfilepaths:\n",
        "        dir_name,filename=os.path.split(thisimg_path)\n",
        "        dir_name=dir_name.replace(folder,dstdir)\n",
        "        new_file_path=os.path.join(dir_name,filename)\n",
        "        if not os.path.exists(dir_name):\n",
        "            os.makedirs(dir_name)\n",
        "        img=cv2.imread(thisimg_path)\n",
        "        img=cv2.resize(img,(224,224))\n",
        "        cv2.imwrite(new_file_path,img)\n",
        "    print('Finish resizing'.format(folder=folder))"
      ],
      "metadata": {
        "id": "GY6_WM9_XlG1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "6AlXBaibSQpK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "DATA_DIR_224='./train_224/'\n",
        "get_224(folder='./train/',dstdir=DATA_DIR_224)\n"
      ],
      "metadata": {
        "id": "E3okmlU-XmdN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "zes0LG2FSRY4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "DATA_DIR2_224='./test_224/'\n",
        "get_224(folder='./test/',dstdir=DATA_DIR2_224)\n"
      ],
      "metadata": {
        "id": "KS6OTip6XsZ4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "2LrHSBZBSR5w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "img1 = Image.open('./train_224/0/100015.png')\n",
        "img2 = Image.open('./train_224/1/10023.png')\n",
        "img3 = Image.open('./train_224/2/10023.png')\n",
        "img4 = Image.open('./train_224/3/10023.png')\n",
        "img5 = Image.open('./train_224/4/10079.png')\n",
        "\n",
        "plt.figure(figsize=(10, 10))\n",
        "plt.subplot(1,5,1)\n",
        "plt.imshow(img1)\n",
        "plt.title(\"Normal\")\n",
        "plt.subplot(1,5,2)\n",
        "plt.imshow(img2)\n",
        "plt.title(\"RPM\")\n",
        "plt.subplot(1,5,3)\n",
        "plt.imshow(img3)\n",
        "plt.title(\"Gear\")\n",
        "plt.subplot(1,5,4)\n",
        "plt.imshow(img4)\n",
        "plt.title(\"Dos\")\n",
        "plt.subplot(1,5,5)\n",
        "plt.imshow(img5)\n",
        "plt.title(\"Fuzzy Attack\")\n",
        "plt.show()  # display it"
      ],
      "metadata": {
        "id": "x9cUP64scHu_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "pfN59_2TSTAI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "---\n",
        "From here actual model begins:\n",
        "\n",
        "---\n",
        "---"
      ],
      "metadata": {
        "id": "k6XLdK8nmlus"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this section :-\n",
        "[1] We'll Generate training and testing images from the dataset in which we have currently created the images\n",
        "\n",
        "[2] Construct the CNN model [VGG-19]\n",
        "\n",
        "[3] Do the hyper parameter Optimization also called as hyper parameter tuning"
      ],
      "metadata": {
        "id": "05O9wcuqnVn0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Notebook 2 for CNN model development:-"
      ],
      "metadata": {
        "id": "FMHGE8KsWmRM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Constructing a CNN Model:-\n",
        "import os\n",
        "import tensorflow\n",
        "from tensorflow.keras.preprocessing.image import  ImageDataGenerator\n",
        "from tensorflow.keras.layers import Dense,Flatten,GlobalAveragePooling2D,Input,Conv2D,MaxPooling2D,Dropout\n",
        "from tensorflow.keras.models import Model,load_model,Sequential\n",
        "import tensorflow.keras.callbacks as kcallbacks\n",
        "import tensorflow.keras\n",
        "from tensorflow.keras.preprocessing.image import load_img,img_to_array\n",
        "import math\n",
        "import random\n",
        "from tensorflow.keras.utils import plot_model\n",
        "import matplotlib.pyplot as plt\n",
        "import sklearn.metrics as metrics\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from sklearn.metrics import accuracy_score,precision_score,recall_score,f1_score\n",
        "from tensorflow.keras.optimizers import Adam"
      ],
      "metadata": {
        "id": "VaucHQsqVrgF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "KXID3TRnSUEk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Generating training and testing images:"
      ],
      "metadata": {
        "id": "jPiFH9WdXWYw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "TARGET_SIZE = (224,224)\n",
        "INPUT_SIZE = (224,224,3)\n",
        "BATCH_SIZE = 128\n",
        "\n",
        "#Normalizing the values\n",
        "\n",
        "train_datagen = ImageDataGenerator(rescale =1./255)\n",
        "test_datagen = ImageDataGenerator(rescale = 1./255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    './train_224/',\n",
        "    target_size = TARGET_SIZE,\n",
        "    batch_size = BATCH_SIZE,\n",
        "    class_mode = 'categorical'\n",
        ")\n",
        "\n",
        "validation_generator = test_datagen.flow_from_directory(\n",
        "    './test_224/',\n",
        "    target_size = TARGET_SIZE,\n",
        "    batch_size = BATCH_SIZE,\n",
        "    class_mode = 'categorical'\n",
        ")"
      ],
      "metadata": {
        "id": "D6MdRP_iXVXX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "lAZq-r0eSVHA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Defining the image plotting functions:\n",
        "\n",
        "Plotting the various graphs for the accuracy, validation accuracy etc."
      ],
      "metadata": {
        "id": "d1FyUcm9YZAk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class LossHistory(tensorflow.keras.callbacks.Callback):\n",
        "\n",
        "    def on_train_begin(self, logs={}):\n",
        "        self.losses = {'batch':[], 'epoch':[]}\n",
        "        self.accuracy = {'batch':[], 'epoch':[]}\n",
        "        self.val_loss = {'batch':[], 'epoch':[]}\n",
        "        self.val_accuracy = {'batch':[], 'epoch':[]}\n",
        "    def on_batch_end(self, batch, logs={}):\n",
        "        self.losses['batch'].append(logs.get('loss'))\n",
        "        self.accuracy['batch'].append(logs.get('accuracy'))\n",
        "        self.val_loss['batch'].append(logs.get('val_loss'))\n",
        "        self.val_accuracy['batch'].append(logs.get('val_accuracy'))\n",
        "    def on_epoch_end(self, epoch, logs={}):\n",
        "        self.losses['epoch'].append(logs.get('loss'))\n",
        "        self.accuracy['epoch'].append(logs.get('accuracy'))\n",
        "        self.val_loss['epoch'].append(logs.get('val_loss'))\n",
        "        self.val_accuracy['epoch'].append(logs.get('val_accuracy'))\n",
        "    def loss_plot(self, loss_type):\n",
        "        iters = range(len(self.losses[loss_type]))\n",
        "        plt.figure()\n",
        "        if loss_type == 'batch' :\n",
        "            # acc\n",
        "            plt.plot(iters, self.accuracy[loss_type], 'r', label='train accuracy')\n",
        "            # loss\n",
        "            plt.plot(iters, self.losses[loss_type], 'g', label='train loss')\n",
        "        if loss_type == 'epoch' :\n",
        "            # acc\n",
        "            plt.plot(iters, self.accuracy[loss_type], 'r', label='train accuracy')\n",
        "            # loss\n",
        "            plt.plot(iters, self.losses[loss_type], 'g', label='train loss')\n",
        "            # val_acc\n",
        "            plt.plot(iters, self.val_accuracy[loss_type], 'b', label='val accuracy')\n",
        "            # val_loss\n",
        "            plt.plot(iters, self.val_loss[loss_type], 'k', label='val loss')\n",
        "        plt.grid(True)\n",
        "        plt.xlabel(loss_type)\n",
        "        plt.ylabel('acc-loss')\n",
        "        plt.legend()\n",
        "        plt.show()"
      ],
      "metadata": {
        "id": "o_4-Qh9zYYJ1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "_vGRqzMrSWCy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "  history_this = LossHistory()"
      ],
      "metadata": {
        "id": "5Tli76QlYuse"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "YoAY_nclSWqK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Constructing the CNN model:"
      ],
      "metadata": {
        "id": "1-vxVghciJ5m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#VGG 19 is used:\n",
        "import tensorflow as tf\n",
        "import tensorflow.keras\n",
        "from tensorflow.keras.applications.vgg19 import VGG19\n",
        "def vgg19( num_class, epochs,frozen = 19, lr= 0.001, patience = 2,dropout_rate = 0.5, savepath='./VGG19.h5',history=history_this,input_shape=INPUT_SIZE):\n",
        "    model_fine_tune = VGG19(include_top=False, weights='imagenet', input_shape=(224,224,3))\n",
        "    for layer in model_fine_tune.layers[:19]:\t#the number of frozen layers for transfer learning, have tuned from 5-18\n",
        "        layer.trainable = False\n",
        "    for layer in model_fine_tune.layers[19:]:\n",
        "        layer.trainable = True\n",
        "    model = GlobalAveragePooling2D()(model_fine_tune.output)\n",
        "    model=Dense(units=256,activation='relu')(model)\n",
        "    model=Dropout(0.5)(model)\n",
        "    model = Dense(num_class, activation='softmax')(model)\n",
        "    model = Model(model_fine_tune.input, model, name='vgg')\n",
        "    opt = tf.keras.optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\t#tuned learning rate to be 0.001\n",
        "    model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy', tf.keras.metrics.SensitivityAtSpecificity(0.5), tf.keras.metrics.FalsePositives(),tf.keras.metrics.TruePositives(),tf.keras.metrics.TrueNegatives(),tf.keras.metrics.FalseNegatives()])\t#set the loss function to be binary crossentropy\n",
        "    #train model\n",
        "    earlyStopping = kcallbacks.EarlyStopping(\n",
        "        monitor='val_accuracy', patience=3, verbose=1, mode='auto')\t#set early stop patience to save training time\n",
        "    saveBestModel = kcallbacks.ModelCheckpoint(\n",
        "        filepath=savepath,\n",
        "        monitor='val_accuracy' ,\n",
        "        verbose=1,\n",
        "        save_best_only=True,\n",
        "        mode='auto')\n",
        "    hist = model.fit_generator(\n",
        "        train_generator,\n",
        "        steps_per_epoch=len(train_generator),\n",
        "        epochs=epochs,\n",
        "        validation_data=validation_generator,\n",
        "        validation_steps=len(validation_generator),\n",
        "        use_multiprocessing=True,\n",
        "        # workers=2,\n",
        "        callbacks=[saveBestModel, history],\n",
        "    )"
      ],
      "metadata": {
        "id": "4JrcOiJ3iJL-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "PO0RdyAlSXlQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vgg19(num_class=5,epochs=2)"
      ],
      "metadata": {
        "id": "dmaNmIAkidHt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "bueNF5_tSYWB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The Parameters Calculated at 5th Epoch are as follows:\n",
        "\n",
        "---\n",
        "\n",
        "[1] False Positive: 5.00\n",
        "\n",
        "---\n",
        "\n",
        "[2] True Positive: 23378.00\n",
        "\n",
        "---\n",
        "\n",
        "[3] True Negative: 93527.00\n",
        "\n",
        "---\n",
        "\n",
        "[4] False Negative: 5.00\n",
        "\n",
        "---\n",
        "\n",
        "[5] FPR (False Positive Rate) = 0.001\n",
        "\n",
        "---\n",
        "\n",
        "[6]TPR(True Positive Rate) ="
      ],
      "metadata": {
        "id": "76-i5o9tQtrp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "history_this.loss_plot('epoch')\n",
        "history_this.loss_plot('batch')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Bl6zPPMgT6-v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "x6YFaiDTSZQ1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "---\n",
        "From here testing model starts:\n",
        "\n",
        "---\n",
        "---"
      ],
      "metadata": {
        "id": "oO7DogN0qyIj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.utils import plot_model\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint, LearningRateScheduler\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "import operator\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from collections import defaultdict"
      ],
      "metadata": {
        "id": "R0IoA8xugz6p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "fzi4BeE7SZ8o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_datagen = ImageDataGenerator(rescale = 1./255)\n",
        "validation_generator = test_datagen.flow_from_directory(\n",
        "    './test_224/',\n",
        "    target_size = TARGET_SIZE,\n",
        "    batch_size = BATCH_SIZE,\n",
        "    class_mode = 'categorical'\n",
        ")"
      ],
      "metadata": {
        "id": "7j5xc85Jq5oE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "pHxwWtwsSa2U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "label=validation_generator.class_indices\n",
        "label={v: k for k, v in label.items()}"
      ],
      "metadata": {
        "id": "En8NMJ9JrIoq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "ji87nygjSbYA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(label)"
      ],
      "metadata": {
        "id": "enuTTNuCrkFj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "F_bzhM5uSbyA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rootdir = './test_224/'\n",
        "test_laels = []\n",
        "test_images = []\n",
        "for subdir, dirs, files in os.walk(rootdir):\n",
        "  for file in files:\n",
        "    if not(file.endswith(\".jpeg\"))|(file.endswith(\".png\"))|(file.endswith(\".jpg\")):\n",
        "      continue\n",
        "    test_laels.append(subdir.split('/')[-1])\n",
        "    test_images.append(os.path.join(subdir, file))\n",
        "\n",
        "print(test_laels[0],test_images[0])"
      ],
      "metadata": {
        "id": "H1a4SfhFrox7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "atJGrUwiScWl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vgg19_model = load_model('./VGG19.h5')"
      ],
      "metadata": {
        "id": "4xb8eNImtZBE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "mGkRztZgSc49"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Single image prediction\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "test=cv2.imread('/content/train_224/3/10023.png')\n",
        "# print(test)\n",
        "img_show=test[:,:,[2,1,0]]\n",
        "# print(img_show)\n",
        "test=test/255.\n",
        "test_shape=(1,)+test.shape\n",
        "test=test.reshape(test_shape)\n",
        "\n",
        "res=vgg19_model.predict(test)\n",
        "\n",
        "prob=res[0,np.argmax(res,axis=1)[0]]\n",
        "res=label[np.argmax(res,axis=1)[0]]\n",
        "print(res)\n",
        "if res == '4' :\n",
        "  res = 'Fuzzy'\n",
        "elif res == '2':\n",
        "  res = 'Gear'\n",
        "elif res == '1':\n",
        "  res = 'RPM'\n",
        "elif res == '3':\n",
        "  res = 'DoS'\n",
        "elif res == '0' :\n",
        "  res = 'Normal'\n",
        "else :\n",
        "  print('invalid image')\n",
        "# print(type(res))\n",
        "print('Predicted result for the first image: %s'%res)\n",
        "print('Confidence level: %s'%prob)\n",
        "plt.imshow(img_show)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Ei8g6CyrvX_6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "SQ9ReGhPSd2o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "import time\n",
        "predict=[]\n",
        "length=len(test_images)\n",
        "t1 = time.time()\n",
        "for i in range(length):\n",
        "    inputimg=test_images[i]\n",
        "    test_batch=[]\n",
        "    thisimg=np.array(Image.open(inputimg))/255 #read all the images in validation set\n",
        "    print(thisimg)\n",
        "    test_shape=(1,)+thisimg.shape\n",
        "    thisimg=thisimg.reshape(test_shape)\n",
        "    vgg19_model_batch=vgg19_model.predict(thisimg)\n",
        "    #use master model to process the input image\n",
        "    #generate result by model 1\n",
        "    prob=vgg19_model_batch[0,np.argmax(vgg19_model_batch,axis=1)[0]]\n",
        "    res=label[np.argmax(vgg19_model_batch,axis=1)[0]]\n",
        "    predict.append(res)\n",
        ""
      ],
      "metadata": {
        "id": "-yAXwMagM4zd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "vPyeJ9msSegA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score,precision_score,recall_score,f1_score\n",
        "acc=accuracy_score(test_laels,predict)\n",
        "pre=precision_score(test_laels,predict,average='weighted')\n",
        "re=recall_score(test_laels,predict,average='weighted')\n",
        "f1=f1_score(test_laels,predict,average='weighted')\n",
        "# FPR = tf.metrics.\n",
        "print('VGG19 accuracy: %s'%acc)\n",
        "print('precision: %s'%pre)\n",
        "print('recall: %s'%re)\n",
        "print('f1: %s'%f1)\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "print(confusion_matrix(test_laels, predict))\n",
        "target_names = ['0','1','2','3','4']\n",
        "print(classification_report(test_laels, predict, target_names=target_names))"
      ],
      "metadata": {
        "id": "YuRfADpYYQnL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The Above are the various parameters for the testing done."
      ],
      "metadata": {
        "id": "0_1PgvQdSgAA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "ax = sns.heatmap(confusion_matrix(test_laels, predict),annot= True, cmap='Blues')\n",
        "ax.xaxis.set_ticklabels(['Normal','Fuzzy','DoS','RPM','Gear'])\n",
        "ax.yaxis.set_ticklabels(['Normal','Fuzzy','DoS','RPM','Gear'])\n",
        "plt.show\n"
      ],
      "metadata": {
        "id": "b3IFZmgRQjLc"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}